#include "../raytracing/data_structures.glsl"
layout(local_size_x = 32, local_size_y = 32, local_size_z = 1) in;

#ifndef HISTORY_COUNT
#define HISTORY_COUNT 4
#endif

#ifdef HISTORY_COUNT
layout (binding = 0, set = 0, rgba32f) uniform readonly image2D historyAlbedo[HISTORY_COUNT];
layout (binding = 1, set = 0, rgba32f) uniform readonly image2D historyNormalDepth[HISTORY_COUNT];
layout (binding = 2, set = 0, rgba32f) uniform readonly image2D historyMotion[HISTORY_COUNT];
layout (binding = 3, set = 0) uniform CameraHistory
{
    CameraProperties properties[HISTORY_COUNT];
} camera_history;

layout (binding = 4, set = 0) uniform CameraProperties camera;
layout(binding = 4, set = 0) writeonly uniform image2D outputImage;
#endif
void main()
{
    ivec2 pixelCoord = ivec2(gl_GlobalInvocationID.xy);
    //make sure we don't access past the buffer size
    //------------------------denoising-------------------------
    ivec2 texture_space_coord = ivec2(gl_GlobalInvocationID.xy);

    vec2 uv = ((vec2(gl_LaunchIDEXT.xy) +vec2(0.5)) / vec2(gl_LaunchSizeEXT.xy));
    uint historySampleCount = 1;
    vec3 fragment_world_space_position = origin.xyz + (payload.hit_t * direction.xyz);
    int current_history_index = int(mod(frame.data.index, HISTORY_COUNT));
    for (int i = 1; i < HISTORY_COUNT-1; i++)
    {
        if (frame.data.index - i < 0)
        break;

        texture_space_coord = ivec2(floor(uv * vec2(gl_LaunchSizeEXT.xy)));
        uv -= imageLoad(historyMotion[current_history_index], texture_space_coord).xy;
        texture_space_coord = ivec2(floor(uv* vec2(gl_LaunchSizeEXT.xy)));
        current_history_index = int(mod(frame.data.index - i, HISTORY_COUNT));

        //this fragment was not in the history frame
        if (max(uv.x, uv.y) > 1.0 || min(uv.x, uv.y) < 0.0)
        {
            //color += vec3(1, 0, 0);
            //historySampleCount++;
            continue;
        }

        mat4 history_proj_mat = camera_history.properties[current_history_index].projection;
        mat4 history_transform_mat = camera_history.properties[current_history_index].transform;
        vec2 history_centered_uvs = uv * 2.0 - 1.0;
        vec4 history_origin = history_transform_mat * vec4(0, 0, 0, 1);

        vec4 history_target = inverse(camera_proj_mat) * vec4(history_centered_uvs.x, history_centered_uvs.y, 1, 1);

        float history_t_ratio = imageLoad(historyNormalDepth[current_history_index], texture_space_coord).w;
        float history_t = (1.0-history_t_ratio)* tmax;
        vec4 history_direction = normalize(history_transform_mat * vec4(normalize(history_target.xyz), 0));
        vec4 history_world_space_position = history_origin + (history_t * history_direction);
        // this fragment was occluded in the history frame
        if (distance(fragment_world_space_position, history_world_space_position.xyz) > mix(0.1, 4.0f, history_t_ratio)
        //todo: add edge detection
        )
        {
            //color += vec3(0, 0, 1);
            //historySampleCount ++;
            continue;
        }

        //sample history color
        color += imageLoad(historyAlbedo[current_history_index], texture_space_coord).rgb;

        historySampleCount++;
    }

    color /= float(historySampleCount);
    //const float gamma = frame.data.gamma;
    //float exposure = frame.data.exposure;
    ////tone mapping
    //vec3 mapped = vec3(1.0) - exp(- color * exposure);
    ////exposure
    //mapped = pow(mapped, vec3(1.0 / gamma));

    imageStore(outputImage, ivec2(gl_LaunchIDEXT.xy), vec4(mapped, 1.0));
}
